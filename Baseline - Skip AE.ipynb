{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3c1f47-6e9c-4e56-a255-939f8178a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba60486-a465-4823-b8a5-d223f95fe93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluator import evaluate\n",
    "from data_loader import load_kdd_cup_urc, load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4, load_power_demand # Univariate Datasets\n",
    "from data_loader import load_nasa, load_ecg, load_gesture, load_smd # Multivariate Datasets\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Reshape, Dropout, GaussianNoise, Concatenate, Lambda, RepeatVector\n",
    "\n",
    "# THESE LINES ARE FOR REPRODUCIBILITY\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0f1ab4-164a-4fab-82e3-e42045ec6cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SKip_AE(seq_length, dim, N_RES=3, N_LAYERS=1, BATCH_SIZE=128):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    en_inputs = []\n",
    "    shared_latents = []\n",
    "    for n in range(N_RES):\n",
    "        selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "        en_input = Input(shape=[len(selected_t), dim])\n",
    "        en_inputs.append(en_input)\n",
    "\n",
    "    de_outputs = []\n",
    "    for n in range(N_RES):\n",
    "        for l in range(N_LAYERS):\n",
    "            X = en_inputs[n] if l == 0 else X\n",
    "            X = GaussianNoise(0.5)(X) if l == 0 else X\n",
    "            X = LSTM(64, return_sequences=False if l + 1 == N_LAYERS else True)(X)\n",
    "        h = Dense(32, activation='relu', kernel_regularizer='l1')(X)\n",
    "        shared_latents.append(h)\n",
    "\n",
    "    for n in range(N_RES):\n",
    "        selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "        for l in range(N_LAYERS):\n",
    "            if l == 0:\n",
    "                X = Concatenate()(shared_latents)\n",
    "                X = Dense(128, activation='relu')(X)\n",
    "                X = Concatenate()([X, shared_latents[n]])\n",
    "                X = RepeatVector(len(selected_t))(X)\n",
    "            X = LSTM(64, return_sequences=False if l + 1 == N_LAYERS else True)(X)\n",
    "        rec_x = Dense(len(selected_t) * dim)(X)\n",
    "        rec_x = Reshape([len(selected_t), dim])(rec_x)\n",
    "        de_outputs.append(rec_x)\n",
    "\n",
    "    model = Model(inputs=en_inputs, outputs=de_outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceba82a-7e10-4058-92aa-9b12874ff37d",
   "metadata": {},
   "source": [
    "### Yahoo S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ebab6a-0bb8-466c-bac2-1c15fb237ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb543b5-1d55-4b47-ae21-e8bdeafaa8d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de87a47047d44c8eb785b8475e96f40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7d9f412e144633a87c6201123e4366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yahoo_A1 0.5714285224489823 0.1666666623148149 0.1666666583333337\n",
      "yahoo_A1 0.0 0.0 -0.0\n",
      "yahoo_A1 0.9999998500000123 0.49999990000001493 0.9999998888889001\n",
      "yahoo_A1 0.0 0.0 0.0\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4247b99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "yahoo_A1 0.0 0.0 0.0\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3f8063550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "yahoo_A1 0.0 0.0 -0.0\n",
      "yahoo_A1 0.0 0.0 0.0\n",
      "yahoo_A1 0.46153841893491365 0.14999999350000026 0.49999997619047704\n",
      "yahoo_A1 0.6666666133333363 0.6666666005092657 0.6249999718750009\n",
      "yahoo_A1 0.0 0.0 0.0\n",
      "yahoo_A1 0.7999999200000041 0.6767856563734693 0.6666666311111126\n",
      "yahoo_A1 0.33333330000000166 0.055555557160493235 0.49999994375000567\n",
      "yahoo_A1 0.8888888296296326 0.652777698252327 0.6666665777777875\n",
      "yahoo_A1 0.6666666133333363 0.08333334749999795 -0.0\n",
      "yahoo_A1 0.9999999000000052 0.7499998875000143 0.9999999375000035\n",
      "yahoo_A1 0.18181816198347142 0.0 0.0\n",
      "yahoo_A1 0.46153841893491365 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for loader in [load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4]:\n",
    "    datasets = loader(128, 32)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "        \n",
    "        N_RES = 3\n",
    "\n",
    "        seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "        X_train_reverse = np.flip(X_train, axis=1)\n",
    "        X_test_reverse = np.flip(X_test, axis=1)\n",
    "\n",
    "        X_train_by_res = []\n",
    "        X_test_by_res = []\n",
    "        X_train_by_res_reverse = []\n",
    "        \n",
    "        for n in range(N_RES):\n",
    "            selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "            X_train_by_res.append(X_train[:, selected_t, :])\n",
    "            X_test_by_res.append(X_test[:, selected_t, :])\n",
    "            X_train_by_res_reverse.append(X_train_reverse[:, selected_t, :])\n",
    "        \n",
    "        model = SKip_AE(seq_length, dim, N_RES, N_LAYERS=2, BATCH_SIZE=128)\n",
    "        history = model.fit(X_train_by_res, X_train_by_res_reverse, epochs=50, batch_size=128, validation_split=0.3, verbose=0,\n",
    "                            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "        \n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test_by_res)]\n",
    "        scores = evaluate(X_test, X_test_rec[0], y_tests[i], is_reconstructed=True)\n",
    "    \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba871981-8985-4f94-ba02-f11bee44bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_results = pd.DataFrame(total_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99fe44-ecce-4e74-a326-9a1718b62f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b544c-01d5-40dc-8c82-17002ca08ae8",
   "metadata": {},
   "source": [
    "### NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10eaa5-4d09-4617-8ec2-004069465222",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19d991-dde5-49d1-b4db-52af438c7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_nasa]:\n",
    "    datasets = loader(100, 100)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        N_RES = 3\n",
    "\n",
    "        seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "        X_train_reverse = np.flip(X_train, axis=1)\n",
    "        X_test_reverse = np.flip(X_test, axis=1)\n",
    "\n",
    "        X_train_by_res = []\n",
    "        X_test_by_res = []\n",
    "        X_train_by_res_reverse = []\n",
    "        \n",
    "        for n in range(N_RES):\n",
    "            selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "            X_train_by_res.append(X_train[:, selected_t, :])\n",
    "            X_test_by_res.append(X_test[:, selected_t, :])\n",
    "            X_train_by_res_reverse.append(X_train_reverse[:, selected_t, :])\n",
    "        \n",
    "        model = SKip_AE(seq_length, dim, N_RES, N_LAYERS=2, BATCH_SIZE=128)\n",
    "        history = model.fit(X_train_by_res, X_train_by_res_reverse, epochs=50, batch_size=128, validation_split=0.3, verbose=0,\n",
    "                            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "        \n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test_by_res)]\n",
    "        scores = evaluate(X_test, X_test_rec[0], y_tests[i], is_reconstructed=True)\n",
    "        \n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358182d-2dd7-48b7-9c45-6b863091e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_results = pd.DataFrame(total_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3704393-78a8-4bcb-8b4b-a2ebf4ca08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d211db-832e-4e04-98d2-f24cd026d8e4",
   "metadata": {},
   "source": [
    "### SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a32fb1-9d33-401a-99ca-b5b88fec0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9f650-8648-4626-a041-52daf5aa1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_smd]:\n",
    "    datasets = loader(100, 100)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        N_RES = 3\n",
    "\n",
    "        seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "        X_train_reverse = np.flip(X_train, axis=1)\n",
    "        X_test_reverse = np.flip(X_test, axis=1)\n",
    "\n",
    "        X_train_by_res = []\n",
    "        X_test_by_res = []\n",
    "        X_train_by_res_reverse = []\n",
    "        \n",
    "        for n in range(N_RES):\n",
    "            selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "            X_train_by_res.append(X_train[:, selected_t, :])\n",
    "            X_test_by_res.append(X_test[:, selected_t, :])\n",
    "            X_train_by_res_reverse.append(X_train_reverse[:, selected_t, :])\n",
    "        \n",
    "        model = SKip_AE(seq_length, dim, N_RES, N_LAYERS=2, BATCH_SIZE=128)\n",
    "        history = model.fit(X_train_by_res, X_train_by_res_reverse, epochs=50, batch_size=128, validation_split=0.3, verbose=0,\n",
    "                            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "        \n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test_by_res)]\n",
    "        scores = evaluate(X_test, X_test_rec[0], y_tests[i], is_reconstructed=True)\n",
    "      \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091c8f3-f45f-4ed8-bbb8-fa3fbf49431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_results = pd.DataFrame(total_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c76453-459e-4743-84a0-ab503cc46c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_results.groupby('dataset').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
