{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147cd176-7bf7-40ca-84a5-1b3401cbf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb3df11-ae49-4f59-8515-a2c3c85bb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluator import evaluate\n",
    "from data_loader import load_kdd_cup_urc, load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4, load_power_demand # Univariate Datasets\n",
    "from data_loader import load_nasa, load_ecg, load_gesture, load_smd # Multivariate Datasets\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, LSTMCell, GRU, GRUCell, Reshape, Dropout, GaussianNoise, Concatenate, Lambda, RepeatVector, TimeDistributed, Add\n",
    "\n",
    "# THESE LINES ARE FOR REPRODUCIBILITY\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1c631e-10e2-48ad-b6ac-93c69cdf9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipRNN(tf.keras.layers.Layer):\n",
    "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.get_initial_state = getattr(\n",
    "            self.cell, \"get_initial_state\", self.fallback_initial_state)\n",
    "    def fallback_initial_state(self, inputs):\n",
    "        return [tf.zeros([self.cell.state_size], dtype=inputs.dtype)]\n",
    "    @tf.function\n",
    "    def call(self, inputs, states=None):\n",
    "        states = self.get_initial_state(inputs) if states == None else states\n",
    "\n",
    "        outputs = tf.zeros(shape=[self.cell.output_size], dtype=inputs.dtype)\n",
    "        outputs, states = self.cell(inputs, states)\n",
    "\n",
    "        return outputs, states\n",
    "    \n",
    "def Modified_S_RNN(X_train):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    sparseness_weights = [(0, 1), (1, 0), (1, 1)]\n",
    "    BATCH_SIZE = 128\n",
    "    N, N_LAYERS, N_UNITS = 3, 1, 64\n",
    "\n",
    "    X_train_reverse = np.flip(X_train, axis=1)\n",
    "    seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "    en_input = Input(shape=[seq_length, dim])\n",
    "    X = GaussianNoise(0.1)(en_input)\n",
    "    initial_states = tf.zeros([BATCH_SIZE, N_UNITS])\n",
    "\n",
    "    shared_latents = []\n",
    "    for i in range(N):\n",
    "        prev_states = []\n",
    "        skip_length = 2**i\n",
    "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
    "        w = w1 + w2\n",
    "\n",
    "        for t in range(seq_length):\n",
    "            Xt = Lambda(lambda x: x[:, t, :])(X)\n",
    "            if t == 0:\n",
    "                O, H = SkipRNN(GRUCell(N_UNITS))(Xt)\n",
    "            else:\n",
    "                if t - skip_length >= 0:\n",
    "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
    "                    O, H = SkipRNN(GRUCell(N_UNITS))(Xt, prev_states[t-1])\n",
    "                else:\n",
    "                    O, H = SkipRNN(GRUCell(N_UNITS))(Xt, prev_states[t-1])\n",
    "\n",
    "            prev_states.append(H)\n",
    "        shared_latents.append(H)\n",
    "\n",
    "    de_outputs = []\n",
    "    de_input = Concatenate()(shared_latents)\n",
    "    D_shared = Dense(dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005))(de_input)\n",
    "\n",
    "    for i in range(N):\n",
    "        Y_i = []\n",
    "        prev_states = []\n",
    "        skip_length = 2**i\n",
    "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
    "        w = w1 + w2\n",
    "        \n",
    "        D_each = Dense(dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005))(shared_latents[i])\n",
    "\n",
    "        D = Concatenate()([D_shared, D_each])\n",
    "        D = Dense(dim)(D)\n",
    "\n",
    "        for t in range(seq_length):\n",
    "            if t == 0:\n",
    "                y = Dense(dim)(D)\n",
    "                _, H = SkipRNN(GRUCell(dim))(y, D) # y_t\n",
    "            else:\n",
    "                if t - skip_length >= 0:\n",
    "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
    "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], states) # y_t-1 --> y_1\n",
    "                else:\n",
    "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], prev_states[t-1]) # y_t-1 --> y_1\n",
    "\n",
    "            Y_i.append(y)\n",
    "            prev_states.append(H)\n",
    "\n",
    "        Y_i = Concatenate()(Y_i)\n",
    "        Y_i = Reshape([seq_length, dim])(Y_i)\n",
    "        de_outputs.append(Y_i)\n",
    "\n",
    "    model = Model(inputs=en_input, outputs=de_outputs)\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay( initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=2.5), loss='mse')\n",
    "\n",
    "    history = model.fit(X_train, [X_train_reverse for _ in range(N)], batch_size=BATCH_SIZE, epochs=50, validation_split=0.3, verbose=0, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c74d6c-977c-4318-ae7c-626e051a4bfd",
   "metadata": {},
   "source": [
    "### Yahoo S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc47be27-622e-4585-8449-c653f81d2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac394fa-ab18-4f88-b98a-69711cb11dd8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918b2df4b40b4633b379b9960f5c8a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662fc0913797419fa35d8f4e252547d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yahoo_A1 0.9999999000000052 0.4999999375000063 0.9999999490291289\n"
     ]
    }
   ],
   "source": [
    "for loader in [load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4]:\n",
    "    datasets = loader(8, 4)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "        \n",
    "        model = Modified_S_RNN(X_train)\n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test)]\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True, scoring='square_median')\n",
    "    \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14b22-b9e6-48fd-9b16-0813b54c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_results = pd.DataFrame(total_scores)\n",
    "yahoo_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b88ce-b8c6-4413-94be-a5178fa2ceab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb798ddf-37a1-49cf-91f3-ee919f49cb23",
   "metadata": {},
   "source": [
    "### NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76c8d0-240c-414f-8e88-bb653cc38282",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec506f-03ba-4ff5-a539-576461d3f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_nasa]:\n",
    "    datasets = loader(8, 4)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = Modified_S_RNN(X_train)\n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test)]\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True, scoring='square_median')\n",
    "        \n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54a19a-5e17-4d33-86bd-d8a95582b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_results = pd.DataFrame(total_scores)\n",
    "nasa_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b53de-5985-46d7-903a-fa995e5152e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ac064c7-60c2-4977-b5bb-ac9369129ded",
   "metadata": {},
   "source": [
    "### SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83be971-b601-4769-bbb8-c5ea395b6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508947a2-0bed-4e4b-bda9-23d132ca16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_smd]:\n",
    "    datasets = loader(8, 4)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = Modified_S_RNN(X_train)\n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test)]\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True, scoring='square_median')\n",
    "      \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d8ddb-3e7c-475d-81f4-403074ae55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_results = pd.DataFrame(total_scores)\n",
    "smd_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cfdc7-5631-41a4-bac4-84b6975e46a9",
   "metadata": {},
   "source": [
    "### ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde51e6e-9fa2-4f36-9d54-8bef73fad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a370859-5d52-4844-8570-d10e94bc6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_ecg]:\n",
    "    datasets = loader(4, 2)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = Modified_S_RNN(X_train)\n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test)]\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True, scoring='square_median')\n",
    "\n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647994fa-8099-4900-9bc0-60b0de7bb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_results = pd.DataFrame(total_scores)\n",
    "ecg_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b1b43-0758-4478-b91c-136380588607",
   "metadata": {},
   "source": [
    "### Power Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae67ae-17d2-4201-90b2-3d4c3861731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485a47d-8c25-4caa-a398-80d25360b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_power_demand]:\n",
    "    datasets = loader(16, 8)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = Modified_S_RNN(X_train)\n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test)]\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True, scoring='square_median')\n",
    "\n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a1a89-b2f4-4ebc-b4b9-4a364e5303f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_results = pd.DataFrame(total_scores)\n",
    "power_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2165c-1cd4-4200-bf67-26207d393e05",
   "metadata": {},
   "source": [
    "### 2D Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61678d-28c7-4835-b1b2-ee6593988c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4638af-57eb-4bce-8a52-5bd01d7683a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_gesture]:\n",
    "    datasets = loader(4, 2)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = Modified_S_RNN(X_train)\n",
    "        X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test)]\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True, scoring='square_median')\n",
    "\n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d848e-0877-46d0-b702-7a7ec9513970",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_results = pd.DataFrame(total_scores)\n",
    "gesture_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700effc8-c337-4d0c-a4c4-2781d6c45f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
