{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147cd176-7bf7-40ca-84a5-1b3401cbf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb3df11-ae49-4f59-8515-a2c3c85bb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluator import evaluate\n",
    "from data_loader import load_kdd_cup_urc, load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4, load_power_demand # Univariate Datasets\n",
    "from data_loader import load_nasa, load_ecg, load_gesture, load_smd # Multivariate Datasets\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, LSTMCell, GRU, GRUCell, Reshape, Dropout, GaussianNoise, Concatenate, Lambda, RepeatVector, TimeDistributed\n",
    "\n",
    "# THESE LINES ARE FOR REPRODUCIBILITY\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b20c32-a54a-4726-82b0-dc32c00fca02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b333d-fad8-4a1d-a74d-9b36e98e58f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d688fe0-9698-4e51-bc75-18e9ca6a9ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42caa97ba5be4a7288b8ac887a4a2b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_yahoo_A1(128, 64)\n",
    "X_train, X_test = datasets['x_train'][0], datasets['x_test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1c631e-10e2-48ad-b6ac-93c69cdf9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipRNN(tf.keras.layers.Layer):\n",
    "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.get_initial_state = getattr(self.cell, \"get_initial_state\", self.fallback_initial_state)\n",
    "        \n",
    "    def fallback_initial_state(self, inputs):\n",
    "        return [tf.zeros([self.cell.state_size], dtype=inputs.dtype)]\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        states = self.get_initial_state(inputs)\n",
    "        n_steps = tf.shape(inputs)[1]\n",
    "        \n",
    "        print(n_steps)\n",
    "        \n",
    "#         if self.return_sequences:\n",
    "        sequences = tf.TensorArray(inputs.dtype, size=n_steps)\n",
    "            \n",
    "        outputs = tf.zeros(shape=[n_steps, self.cell.output_size], dtype=inputs.dtype)\n",
    "        \n",
    "        prev_states = []\n",
    "        for step in tf.range(n_steps):\n",
    "            outputs, states = self.cell(inputs[:, step], states)\n",
    "            prev_states.append(states)\n",
    "\n",
    "            if self.return_sequences:\n",
    "                sequences = sequences.write(step, outputs)\n",
    "                \n",
    "        if self.return_sequences:\n",
    "            return sequences.stack()\n",
    "        else:\n",
    "            return outputs\n",
    "        \n",
    "# def MR_TAD(X_train):\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     BATCH_SIZE = 128\n",
    "#     N, N_LAYERS = 3, 1\n",
    "    \n",
    "#     X_train_reverse = np.flip(X_train, axis=1)\n",
    "#     seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "    \n",
    "#     en_input = Input(shape=[seq_length, dim])\n",
    "#     de_output = []\n",
    "    \n",
    "#     for \n",
    "    \n",
    "    \n",
    "#     model = Model(inputs=en_input, outputs=de_outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "543d8ae2-ae4c-4fab-a981-03a2a815d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "N, N_LAYERS, N_UNITS = 3, 1, 64\n",
    "\n",
    "X_train_reverse = np.flip(X_train, axis=1)\n",
    "seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "en_input = Input(shape=[seq_length, dim])\n",
    "X = GaussianNoise(0.5)(en_input)\n",
    "initial_states = tf.zeros([BATCH_SIZE, N_UNITS])\n",
    "\n",
    "shared_latents = []\n",
    "for i in range(N):\n",
    "    prev_states = []\n",
    "    for t in range(seq_length):\n",
    "        states = initial_states if t == 0 else prev_states[t-1]\n",
    "        Xt = Lambda(lambda x: x[:, t, :])(X)\n",
    "        outputs, states = GRUCell(N_UNITS)(Xt, states)\n",
    "        prev_states.append(states)\n",
    "        \n",
    "#     H = SkipRNN(LSTMCell(32))(X)\n",
    "    shared_latents.append(prev_states[t])\n",
    "\n",
    "de_outputs = []\n",
    "de_input = Concatenate()(shared_latents)\n",
    "D = Dense(dim, activation='relu')(de_input)\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    prev_states = []\n",
    "    Y = []\n",
    "    for t in range(seq_length):\n",
    "        states = D if t == 0 else prev_states[t-1]\n",
    "        yt = outputs if t == 0 else Y[t-1]\n",
    "        yt, states = GRUCell(dim)(yt, states)\n",
    "        prev_states.append(states)\n",
    "        Y.append(yt)\n",
    "    Y = Concatenate()(Y)\n",
    "    Y = Reshape([seq_length, dim])(Y)\n",
    "    de_outputs.append(Y)\n",
    "\n",
    "# for i in range(N):\n",
    "# #     H = RepeatVector(seq_length)(D)\n",
    "#     output = LSTMCell(dim)(H)\n",
    "# #     output = TimeDistributed(Dense(dim))(H)\n",
    "# #     output = Reshape([seq_length, dim])(output)\n",
    "#     print(output)\n",
    "#     de_outputs.append(output)\n",
    "\n",
    "model = Model(inputs=en_input, outputs=de_outputs)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "# model.fit(X_train, [X_train_reverse for _ in range(N)], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fb8890d-29d1-429d-a207-55931c25ac65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(128, 64) dtype=float32 (created by layer 'gru_cell_383')>,\n",
       " <KerasTensor: shape=(128, 64) dtype=float32 (created by layer 'gru_cell_382')>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c74d6c-977c-4318-ae7c-626e051a4bfd",
   "metadata": {},
   "source": [
    "### Yahoo S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47be27-622e-4585-8449-c653f81d2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac394fa-ab18-4f88-b98a-69711cb11dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4]:\n",
    "    datasets = loader(128, 64)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         N_RES = 3\n",
    "\n",
    "#         seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "#         X_train_reverse = np.flip(X_train, axis=1)\n",
    "#         X_test_reverse = np.flip(X_test, axis=1)\n",
    "\n",
    "#         X_train_by_res = []\n",
    "#         X_test_by_res = []\n",
    "#         X_train_by_res_reverse = []\n",
    "        \n",
    "#         for n in range(N_RES):\n",
    "#             selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "#             X_train_by_res.append(X_train[:, selected_t, :])\n",
    "#             X_test_by_res.append(X_test[:, selected_t, :])\n",
    "#             X_train_by_res_reverse.append(X_train_reverse[:, selected_t, :])\n",
    "        \n",
    "#         model = SKip_AE(seq_length, dim, N_RES, N_LAYERS=2, BATCH_SIZE=128)\n",
    "#         history = model.fit(X_train_by_res, X_train_by_res_reverse, epochs=50, batch_size=128, validation_split=0.3, verbose=0,\n",
    "#                             callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "        \n",
    "#         X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test_by_res)]\n",
    "#         scores = evaluate(X_test, X_test_rec[0], y_tests[i], is_reconstructed=True)\n",
    "    \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14b22-b9e6-48fd-9b16-0813b54c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_results = pd.DataFrame(total_scores)\n",
    "yahoo_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb798ddf-37a1-49cf-91f3-ee919f49cb23",
   "metadata": {},
   "source": [
    "### NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76c8d0-240c-414f-8e88-bb653cc38282",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec506f-03ba-4ff5-a539-576461d3f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_nasa]:\n",
    "    datasets = loader(128, 64)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        \n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54a19a-5e17-4d33-86bd-d8a95582b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_results = pd.DataFrame(total_scores)\n",
    "nasa_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac064c7-60c2-4977-b5bb-ac9369129ded",
   "metadata": {},
   "source": [
    "### SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83be971-b601-4769-bbb8-c5ea395b6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508947a2-0bed-4e4b-bda9-23d132ca16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_smd]:\n",
    "    datasets = loader(128, 64)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "       \n",
    "      \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d8ddb-3e7c-475d-81f4-403074ae55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_results = pd.DataFrame(total_scores)\n",
    "smd_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cfdc7-5631-41a4-bac4-84b6975e46a9",
   "metadata": {},
   "source": [
    "### ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde51e6e-9fa2-4f36-9d54-8bef73fad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a370859-5d52-4844-8570-d10e94bc6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_ecg]:\n",
    "    datasets = loader(64, 32)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = CNN_VAE(X_train)\n",
    "        \n",
    "        X_test_rec = model.decoder.predict(model.encoder.predict(X_test)[-1])\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True)\n",
    "\n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647994fa-8099-4900-9bc0-60b0de7bb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_results = pd.DataFrame(total_scores)\n",
    "ecg_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b1b43-0758-4478-b91c-136380588607",
   "metadata": {},
   "source": [
    "### Power Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae67ae-17d2-4201-90b2-3d4c3861731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485a47d-8c25-4caa-a398-80d25360b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_power_demand]:\n",
    "    datasets = loader(512, 256)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = CNN_VAE(X_train)\n",
    "        \n",
    "        X_test_rec = model.decoder.predict(model.encoder.predict(X_test)[-1])\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True)\n",
    "\n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a1a89-b2f4-4ebc-b4b9-4a364e5303f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_results = pd.DataFrame(total_scores)\n",
    "power_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2165c-1cd4-4200-bf67-26207d393e05",
   "metadata": {},
   "source": [
    "### 2D Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61678d-28c7-4835-b1b2-ee6593988c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4638af-57eb-4bce-8a52-5bd01d7683a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_gesture]:\n",
    "    datasets = loader(64, 32)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = CNN_VAE(X_train)\n",
    "        \n",
    "        X_test_rec = model.decoder.predict(model.encoder.predict(X_test)[-1])\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True)\n",
    "\n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d848e-0877-46d0-b702-7a7ec9513970",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_results = pd.DataFrame(total_scores)\n",
    "gesture_results.groupby('dataset').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
