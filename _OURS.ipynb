{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147cd176-7bf7-40ca-84a5-1b3401cbf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb3df11-ae49-4f59-8515-a2c3c85bb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluator import evaluate\n",
    "from data_loader import load_kdd_cup_urc, load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4, load_power_demand # Univariate Datasets\n",
    "from data_loader import load_nasa, load_ecg, load_gesture, load_smd # Multivariate Datasets\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, LSTMCell, GRU, GRUCell, Reshape, Dropout, GaussianNoise, Concatenate, Lambda, RepeatVector, TimeDistributed\n",
    "\n",
    "# THESE LINES ARE FOR REPRODUCIBILITY\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b333d-fad8-4a1d-a74d-9b36e98e58f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d688fe0-9698-4e51-bc75-18e9ca6a9ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0186d4c6c344c32a8178a2b9823cbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_yahoo_A1(128, 64)\n",
    "X_train, X_test, y_test = datasets['x_train'][0], datasets['x_test'][0], datasets['y_test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305df8cc-845a-405a-af01-42e00166d601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SkipRNN(tf.keras.layers.Layer):\n",
    "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.get_initial_state = getattr(\n",
    "            self.cell, \"get_initial_state\", self.fallback_initial_state)\n",
    "    def fallback_initial_state(self, inputs):\n",
    "        return [tf.zeros([self.cell.state_size], dtype=inputs.dtype)]\n",
    "    @tf.function\n",
    "    def call(self, inputs, states=None):\n",
    "        states = self.get_initial_state(inputs) if states == None else states\n",
    "\n",
    "        outputs = tf.zeros(shape=[self.cell.output_size], dtype=inputs.dtype)\n",
    "        outputs, states = self.cell(inputs, states)\n",
    "\n",
    "        return outputs, states\n",
    "    \n",
    "def S_RNN(X_train):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    sparseness_weights = [(0, 1), (1, 0), (1, 1)]\n",
    "    BATCH_SIZE = 128\n",
    "    N, N_LAYERS, N_UNITS = 3, 1, 64\n",
    "\n",
    "    X_train_reverse = np.flip(X_train, axis=1)\n",
    "    seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "    en_input = Input(shape=[seq_length, dim])\n",
    "    X = GaussianNoise(0.5)(en_input)\n",
    "    initial_states = tf.zeros([BATCH_SIZE, N_UNITS])\n",
    "\n",
    "    shared_latents = []\n",
    "    for i in range(N):\n",
    "        prev_states = []\n",
    "        skip_length = np.random.randint(low=2, high=10, size=1)[0]\n",
    "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
    "        w = w1 + w2\n",
    "\n",
    "        for t in range(seq_length):\n",
    "            Xt = Lambda(lambda x: x[:, t, :])(X)\n",
    "            if t == 0:\n",
    "                O, H = SkipRNN(GRUCell(32))(Xt)\n",
    "            else:\n",
    "                if t - skip_length >= 0:\n",
    "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
    "                    O, H = SkipRNN(GRUCell(32))(Xt, prev_states[t-1])\n",
    "                else:\n",
    "                    O, H = SkipRNN(GRUCell(32))(Xt, prev_states[t-1])\n",
    "\n",
    "            prev_states.append(H)\n",
    "        shared_latents.append(H)\n",
    "\n",
    "    de_outputs = []\n",
    "    de_input = Concatenate()(shared_latents)\n",
    "    D = Dense(dim, activation='relu')(de_input)\n",
    "\n",
    "    for i in range(N):\n",
    "        Y_i = []\n",
    "        prev_states = []\n",
    "        skip_length = np.random.randint(low=2, high=10, size=1)[0]\n",
    "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
    "        w = w1 + w2\n",
    "\n",
    "        for t in range(seq_length):\n",
    "            if t == 0:\n",
    "                y = Dense(dim)(D)\n",
    "                _, H = SkipRNN(GRUCell(dim))(y, D) # y_t\n",
    "            else:\n",
    "                if t - skip_length >= 0:\n",
    "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
    "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], states) # y_t-1 --> y_1\n",
    "                else:\n",
    "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], prev_states[t-1]) # y_t-1 --> y_1\n",
    "\n",
    "            Y_i.append(y)\n",
    "            prev_states.append(H)\n",
    "\n",
    "        Y_i = Concatenate()(Y_i)\n",
    "        Y_i = Reshape([seq_length, dim])(Y_i)\n",
    "        de_outputs.append(Y_i)\n",
    "\n",
    "    model = Model(inputs=en_input, outputs=de_outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    history = model.fit(X_train, [X_train_reverse for _ in range(N)], batch_size=BATCH_SIZE, epochs=1, validation_split=0.3, verbose=0, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "543d8ae2-ae4c-4fab-a981-03a2a815d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f6d89a0e4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6d23b8baf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "sparseness_weights = [(0, 1), (1, 0), (1, 1)]\n",
    "BATCH_SIZE = 128\n",
    "N, N_LAYERS, N_UNITS = 3, 1, 64\n",
    "\n",
    "X_train_reverse = np.flip(X_train, axis=1)\n",
    "seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "en_input = Input(shape=[seq_length, dim])\n",
    "X = GaussianNoise(0.5)(en_input)\n",
    "initial_states = tf.zeros([BATCH_SIZE, N_UNITS])\n",
    "\n",
    "shared_latents = []\n",
    "for i in range(N):\n",
    "    prev_states = []\n",
    "    skip_length = np.random.randint(low=2, high=10, size=1)[0]\n",
    "    w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
    "    w = w1 + w2\n",
    "    \n",
    "    for t in range(seq_length):\n",
    "        Xt = Lambda(lambda x: x[:, t, :])(X)\n",
    "        if t == 0:\n",
    "            O, H = SkipRNN(GRUCell(32))(Xt)\n",
    "        else:\n",
    "            if t - skip_length >= 0:\n",
    "                states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
    "                O, H = SkipRNN(GRUCell(32))(Xt, prev_states[t-1])\n",
    "            else:\n",
    "                O, H = SkipRNN(GRUCell(32))(Xt, prev_states[t-1])\n",
    "                \n",
    "        prev_states.append(H)\n",
    "    shared_latents.append(H)\n",
    "\n",
    "de_outputs = []\n",
    "de_input = Concatenate()(shared_latents)\n",
    "D = Dense(dim, activation='relu')(de_input)\n",
    "\n",
    "for i in range(N):\n",
    "    Y_i = []\n",
    "    prev_states = []\n",
    "    skip_length = np.random.randint(low=2, high=10, size=1)[0]\n",
    "    w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
    "    w = w1 + w2\n",
    "    \n",
    "    for t in range(seq_length):\n",
    "        if t == 0:\n",
    "            y = Dense(dim)(D)\n",
    "            _, H = SkipRNN(GRUCell(dim))(y, D) # y_t\n",
    "        else:\n",
    "            if t - skip_length >= 0:\n",
    "                states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
    "                y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], states) # y_t-1 --> y_1\n",
    "            else:\n",
    "                y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], prev_states[t-1]) # y_t-1 --> y_1\n",
    "\n",
    "        Y_i.append(y)\n",
    "        prev_states.append(H)\n",
    "    \n",
    "    Y_i = Concatenate()(Y_i)\n",
    "    Y_i = Reshape([seq_length, dim])(Y_i)\n",
    "    de_outputs.append(Y_i)\n",
    "\n",
    "model = Model(inputs=en_input, outputs=de_outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "history = model.fit(X_train, [X_train_reverse for _ in range(N)], batch_size=BATCH_SIZE, epochs=1, validation_split=0.3, verbose=0, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44ce0045-466d-4ca6-badf-4237b3e49993",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rec = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abfed1d8-3621-4130-b975-882fb1217176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 128, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d740579a-57a5-4501-b727-8a5eaf4b1ff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-25a886315161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reconstructed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CS570-Team4-Project/evaluator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(x, rec_x, labels, is_reconstructed, n, scoring, x_val)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mTP_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTN_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFN_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for each time window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;31m# if any part of the segment has an anomaly, we consider it as anomalous sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtrue_anomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_anomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "scores = evaluate(np.flip(X_test, axis=1), X_test_rec, y_test, is_reconstructed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c74d6c-977c-4318-ae7c-626e051a4bfd",
   "metadata": {},
   "source": [
    "### Yahoo S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47be27-622e-4585-8449-c653f81d2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac394fa-ab18-4f88-b98a-69711cb11dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_yahoo_A1, load_yahoo_A2, load_yahoo_A3, load_yahoo_A4]:\n",
    "    datasets = loader(128, 64)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         N_RES = 3\n",
    "\n",
    "#         seq_length, dim = X_train.shape[1], X_train.shape[2]\n",
    "#         X_train_reverse = np.flip(X_train, axis=1)\n",
    "#         X_test_reverse = np.flip(X_test, axis=1)\n",
    "\n",
    "#         X_train_by_res = []\n",
    "#         X_test_by_res = []\n",
    "#         X_train_by_res_reverse = []\n",
    "        \n",
    "#         for n in range(N_RES):\n",
    "#             selected_t = [t for t in range(0, seq_length, 2**n)]\n",
    "#             X_train_by_res.append(X_train[:, selected_t, :])\n",
    "#             X_test_by_res.append(X_test[:, selected_t, :])\n",
    "#             X_train_by_res_reverse.append(X_train_reverse[:, selected_t, :])\n",
    "        \n",
    "#         model = SKip_AE(seq_length, dim, N_RES, N_LAYERS=2, BATCH_SIZE=128)\n",
    "#         history = model.fit(X_train_by_res, X_train_by_res_reverse, epochs=50, batch_size=128, validation_split=0.3, verbose=0,\n",
    "#                             callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)]) \n",
    "        \n",
    "#         X_test_rec = [np.flip(rec, axis=1) for rec in model.predict(X_test_by_res)]\n",
    "#         scores = evaluate(X_test, X_test_rec[0], y_tests[i], is_reconstructed=True)\n",
    "    \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14b22-b9e6-48fd-9b16-0813b54c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_results = pd.DataFrame(total_scores)\n",
    "yahoo_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb798ddf-37a1-49cf-91f3-ee919f49cb23",
   "metadata": {},
   "source": [
    "### NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76c8d0-240c-414f-8e88-bb653cc38282",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec506f-03ba-4ff5-a539-576461d3f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_nasa]:\n",
    "    datasets = loader(128, 64)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        \n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54a19a-5e17-4d33-86bd-d8a95582b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_results = pd.DataFrame(total_scores)\n",
    "nasa_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac064c7-60c2-4977-b5bb-ac9369129ded",
   "metadata": {},
   "source": [
    "### SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83be971-b601-4769-bbb8-c5ea395b6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508947a2-0bed-4e4b-bda9-23d132ca16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_smd]:\n",
    "    datasets = loader(128, 64)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "       \n",
    "      \n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d8ddb-3e7c-475d-81f4-403074ae55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_results = pd.DataFrame(total_scores)\n",
    "smd_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cfdc7-5631-41a4-bac4-84b6975e46a9",
   "metadata": {},
   "source": [
    "### ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde51e6e-9fa2-4f36-9d54-8bef73fad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a370859-5d52-4844-8570-d10e94bc6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_ecg]:\n",
    "    datasets = loader(64, 32)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = CNN_VAE(X_train)\n",
    "        \n",
    "        X_test_rec = model.decoder.predict(model.encoder.predict(X_test)[-1])\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True)\n",
    "\n",
    "        total_scores['dataset'].append(f'D{i+1}')\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(f'D{i+1}', np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647994fa-8099-4900-9bc0-60b0de7bb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_results = pd.DataFrame(total_scores)\n",
    "ecg_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b1b43-0758-4478-b91c-136380588607",
   "metadata": {},
   "source": [
    "### Power Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae67ae-17d2-4201-90b2-3d4c3861731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485a47d-8c25-4caa-a398-80d25360b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_power_demand]:\n",
    "    datasets = loader(512, 256)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = CNN_VAE(X_train)\n",
    "        \n",
    "        X_test_rec = model.decoder.predict(model.encoder.predict(X_test)[-1])\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True)\n",
    "\n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a1a89-b2f4-4ebc-b4b9-4a364e5303f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_results = pd.DataFrame(total_scores)\n",
    "power_results.groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2165c-1cd4-4200-bf67-26207d393e05",
   "metadata": {},
   "source": [
    "### 2D Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61678d-28c7-4835-b1b2-ee6593988c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4638af-57eb-4bce-8a52-5bd01d7683a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [load_gesture]:\n",
    "    datasets = loader(64, 32)\n",
    "    x_trains, x_tests, y_tests = datasets['x_train'], datasets['x_test'], datasets['y_test']\n",
    "    \n",
    "    for i in tqdm(range(len(x_trains))):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        X_train = x_trains[i]\n",
    "        X_test = x_tests[i]\n",
    "\n",
    "        model = CNN_VAE(X_train)\n",
    "        \n",
    "        X_test_rec = model.decoder.predict(model.encoder.predict(X_test)[-1])\n",
    "        scores = evaluate(X_test, X_test_rec, y_tests[i], is_reconstructed=True)\n",
    "\n",
    "        total_scores['dataset'].append(loader.__name__.replace('load_', ''))\n",
    "        total_scores['f1'].append(np.max(scores['f1']))\n",
    "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
    "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
    "        print(loader.__name__.replace('load_', ''), np.max(scores['f1']), scores['pr_auc'], scores['roc_auc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d848e-0877-46d0-b702-7a7ec9513970",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_results = pd.DataFrame(total_scores)\n",
    "gesture_results.groupby('dataset').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
